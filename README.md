# ai_temp_monitor

## The structure

The script `main.py` runs two functions asynchronously: `stream_data` and `plot_temp`. 

- **`plot_temp`**: Plots a graph of the temperature data over time.
- **`stream_data`**: Performs three tasks:
  1. Simulates the streaming of temperature data coming from a sensor.
  2. Checks whether the temperature data lies between specified lower and upper thresholds.
  3. Writes a warning message to a log file whenever the data falls outside the acceptable range.
  4. Trigger an **AI agent** whenever a new warning is generated.

The agent will read the warnings log file, gather relevant information through the provided tools, and attempt to provide a possible explanation for the temperature variation.

---

## AI Agent

The AI agent's task is to provide possible explanations for temperature variations. It does so by gathering and analyzing data using the tools it has been provided with.

The agent consists of:
- **Orchestrator**: Defined in `orchestrator.py`
- **Tools**: 
  - **`week_avg_temp_tool.py`**: Gathers weather information for the week.
  - **`writing_tool.py`**: Responsible for generating a summary of detected warnings, analyzing the information, and offering a possible explanation for the temperature variations.

The orchestrator and the writing tool utilize a **Large Language Model (LLM)**, specifically **gemini-2.0-flash**.
The tool that gathers the weekly average temperature uses a free API from [WeatherAPI](https://www.weatherapi.com/).

The tool framework is defined in `base_tool.py`. It is designed to be flexible, making it easy to add new tools to the orchestrator as needed, which is the intended goal.

### Possible Improvements

Ideally, the orchestrator should be provided with additional tools. For example, a tool that retrieves manufacturing information about the sensor, a tool that provides access to the sensor's location data, and others. I think it becomes interesting when the tool can process large amounts of data that would take much longer for a person to analyze.

For the LLM, I used **gemini-2.0-flash** (because I had a free API key for two months). However, I believe it would be more cost-effective and efficient to use a smaller, local model. When used within a tool, such a model could be fine-tuned with specific data.

---

## The Dataset and Streaming

The data used in this project are mock data obtained from [Kaggle](https://www.kaggle.com/datasets/garystafford/environmental-sensor-data-132k). These mock data were used to build the application.

Of all the available data types in the dataset, only the temperature data were used. The timestamp data is generated by the program when the temperature data is created.

The dataset is first preprocessed and then successively read by a generator function defined in `device_stream.py`.


